sudo iptables -A DOCKER-USER -p tcp -m set --match-set desktop_cloud src -m multiport --dports 80,443,6336,19999 -j ACCEPT
sudo iptables -A DOCKER-USER -p tcp -m set --match-set cdn src -m multiport --dports 80,443,6336 -j ACCEPT
sudo iptables -A DOCKER-USER -s 172.30.0.0/16 -d 172.30.0.0/16 -p tcp -j ACCEPT
sudo iptables -A DOCKER-USER -d 172.30.0.0/16 -p tcp -m multiport --dports 80,443,6336,19999 -j DROP
iptables -I DOCKER-INGRESS -m set ! --match-set cdn src -p tcp -m multiport --dports 80,443,6226 -j DROP

heketi-cli --server http://47.52.200.216:8081 --user admin --secret "XegjrfkLc6oql0ei"
source/class/discuz/discuz_application.php

XN!LZeOENmWa@hkl

wget -c http://mirrors.linuxeye.com/oneinstack-full.tar.gz && tar xzf oneinstack-full.tar.gz && ./oneinstack/install.sh --php_option 4 --phpcache_option 1 --php_extensions zendguardloader,ioncube,sourceguardian,imagick,gmagick,fileinfo,imap,redis,memcached,memcache,swoole,xdebug
==============================
千亿
论坛
账号：admin
密码:yujie484666
计算机型号hasee

优乐
账号 aifei3344
密码 aaa111
Vx&*ToKfKN1@7xuw@.

优发
账号 admin
密码 e68e68e68

乐虎论坛：
admin
管理员密码：
TSeNgVYPxGUNJ8mN

龙八
admin 
ZmL802383.
vlivev7

齐乐
admin 
Aa1234＠124？

亚虎
pt_administ
密码0123456@AEbbs

===============================
chattr -i /etc/passwd
chattr -i /etc/group
chattr -i /etc/shadow
chattr -i /etc/sudoers
chattr -i /etc/gshadow

chattr +i /etc/passwd
chattr +i /etc/group
chattr +i /etc/shadow
chattr +i /etc/sudoers
chattr +i /etc/gshadow
********************************************************************

 #判断是否赋值TAG

[ $GITLAB_TAG_OPTION ] || { 
echo "The value of GITLAB tag is not fetched" 
exit 1
}


 #判断是否赋值TAG

[ $GIT_TAG ] || { 
echo "The value of GITLAB tag is not fetched" 
exit 1
}

********************************************************************
修改rsync 默认目录、文件权限
sed -i '1iincoming chmod = D755,F644' /etc/rsyncd.conf

********************************************************************

jenkins  admin:UxNp3AGImDSedzI0OCwqvJI7OMukyB1M
gitlab_online root:devops123

********************************************************************

rancher 分布式文件系统组件安装
yum install iscsi-initiator-utils -y



********************************************************************

vim docker-stack-zb-web.yml

version: '3'
services:
  redis:
    image: 'bitnami/redis:latest'
    environment:
      #- ALLOW_EMPTY_PASSWORD=yes
      - REDIS_DISABLE_COMMANDS=FLUSHDB,FLUSHALL
      - REDIS_PASSWORD="gsmcredis"
      - TZ="Asia/Shanghai"
    ports:
      - '6389:6379'

  tomcat_vue:
    image: harbor.net/zb/zb_web_tomcat
    ports:
      - "8080:8080"
    deploy:
      replicas: 2
      restart_policy:
        condition: on-failure 
      resources:
        limits:
          memory: 4096M
    environment:
      TZ: "Asia/Shanghai"
    volumes:
      - "../zb_server/config.properties:/usr/local/tomcat/webapps/CODE/WEB-INF/classes/config.properties"
      - "../zb_server/init.properties:/usr/local/tomcat/webapps/CODE/WEB-INF/classes/init.properties"
      - "../zb_server/log4j.properties:/usr/local/tomcat/webapps/CODE/WEB-INF/classes/log4j.properties"
      - "../zb_server/context.xml:/usr/local/tomcat/conf/context.xml"
      - "/home/data/logs/zb_server/:/usr/local/tomcat/logs/"
      - "../zb_server/lib/commons-pool2-2.2.jar:/usr/local/tomcat/lib/commons-pool2-2.2.jar"
      - "../zb_server/lib/jedis-2.5.1.jar:/usr/local/tomcat/lib/jedis-2.5.1.jar"
      - "../zb_server/lib/tomcat8.5-redis-session-manager.jar:/usr/local/tomcat/lib/tomcat8.5-redis-session-manager.jar"

  nginx_frontend:
    image: harbor.net/zb/zb_web_nginx
    ports:
      - "8888:80"
    deploy:
      replicas: 2
      restart_policy:
        condition: on-failure 
    environment:
      TZ: "Asia/Shanghai"
    volumes:
      - '/home/data/logs/zb_nginx/:/var/log/nginx/'

  nginx:
    image: harbor.net/zb/nginx
    ports:
      - "80:80"
      - "443:443"
      - "6226:6226"
    deploy:
      replicas: 2
      restart_policy:
        condition: on-failure 
    environment:
      TZ: "Asia/Shanghai"
    volumes:
      - '../zb_nginx/nginx.conf:/etc/nginx/nginx.conf'
      - '../zb_nginx/conf.d:/etc/nginx/conf.d'
      - '../zb_nginx/conf.d/crt:/etc/nginx/conf.d/crt'
      - '../zb_nginx/conf.d/vhost:/etc/nginx/conf.d/vhost'
      - '../zb_nginx/conf.d/data.txt:/etc/nginx/html/data.txt'
      - '/home/data/logs/nginx/:/var/log/nginx/'    
      
********************************************************************
heketi-cli -s http://47.52.200.216:8081 --user admin --secret "XegjrfkLc6oql0ei" topology load --json=/etc/heketi/rancher-gfs.json


swarm 集群初始化

    docker swarm init --advertise-addr 
    
列出集群节点
    
    docker node ls




        - 创建/更新 Dockerfile
          => 构建镜像 docker build . -t 2.2.2.11/test/nginx
          => 上传镜像 docker push 2.2.2.11/test/nginx
          
        - Harbor仓库
          => 镜像 /test/nginx:latest

        - 部署集群
          => 首次创建服务 docker service create -p 8888:80 --replicas 2 --name nginx 2.2.2.11/test/nginx
          => 更新升级 docker service update --image 2.2.2.11/test/nginx nginx


/=========\
| rancher |
\=========/

指定版本安装docker
yum install -y yum-utils

yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo

yum install -y --setopt=obsoletes=0 docker-ce-17.03.2.ce-1.el7.centos.x86_64 docker-ce-selinux-17.03.2.ce-1.el7.centos.noarch

systemctl start docker

********************************************************************
设置镜像仓库
 
cat > /etc/docker/daemon.json << EOF
{
    "insecure-registries": [
        "2.2.2.13"
    ]
}
EOF

********************************************************************
```
FROM harbor.easydevops.net/origin-images/tomcat:8.5-jre8-alpine
COPY lib/commons-pool2-2.2.jar /usr/local/tomcat/lib/
COPY lib/jedis-2.5.1.jar /usr/local/tomcat/lib/
COPY lib/tomcat8.5-redis-session-manager.jar /usr/local/tomcat/lib/
```
curl https://releases.rancher.com/install-docker/17.03.sh | sh

docker run -d --restart=unless-stopped -p 80:80 -p 443:443 2.2.2.11/rancher/rancher:latest


---------------------
获取组件状态  
    kubectl get cs

获取节点健康状态
    kubectl get node

获取环境信息
    kubectl cluster-info

通过文件创建pod
    kubectl create -f *.yaml
     
查询控制器
    kubectl get rc

查询pod
    kubectl get pod
    
删除控制器
    kubectl delete cs xxx

删除服务
    kubectl delete services xxx
---------------------

Pod 管理


创建yaml文件
# vim hello-world-pod.yaml

apiVersion: v1                              #声明kubernetes的API版本
kind: Pod                                   #声明API对象类型
matedata:                                   #设置Pod的元数据
  name: hello-world                         #指定Pod名称，在命名空间中必须唯一
spec:                                       #配置Pod的具体规格
  restartPolicy: Onfailure                  #设置Pod的重启策略
  containers:                               #设置Pod中容器规格
  - name: hello                             #指定容器的名称，在Pod中必须唯一
    image: "centos"                         #指定镜像
    command: ["/bin/echo","Hello","World"]  #设置容器启动指令

创建Pod
# kubectl create -f hello-world-pod.yaml

查询Pod
# kubectl get pod hello-world

查询Pod输出
# kubectl logs hello-world

查询pod的状态和生命周期事件
# kubectl describe pod hello-world

删除Pod
# kubectl delete pod hello-world

更新Pod
# kubectl replace /path/to/my-pod.yaml
注：Pod很多属性是没有办法修改的，如镜像，这是使用--force，等效于重建Pod

镜像下载策略
imagePullPolicy：
    Always 每次下载最新的镜像
    Never  只使用本地镜像，从不下载
    IfNotPresent  只有本地没有的时候才下载镜像   

/=================\
| jenkins install |
\=================/
  下载地址 
  http://updates.jenkins-ci.org/download/war/
  安装tomcat
  # yum install tomcat -y
  
  复制jenkins.war到tomcat应用根目录
  # cp jenkins.war /var/lib/tomcat/webapps/
  
  启动tomcat
  # systemctl restart tomcat

  直接启动
  nohup java -jar jenkins.war &


/================\
| gitlab install |
\================/
  # yum install -y curl policycoreutils openssh-server openssh-clients postfix 
  # systemctl restart postfix
  # systemctl enable postfix
  # curl -sS https://packages.gitlab.com/install/repositories/gitlab/gitlab-ce/script.rpm.sh | sudo bash
  # yum install -y  gitlab-ce

/==============================\
| docker compose install（pip）|
\==============================/
install docker
# yum install -y yum-utils
# yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo
# yum install docker-ce -y
# systemctl enable docker
# systemctl start docker

install pip（need epel）
# yum install -y epel-release
# yum install -y python-pip
# pip install --upgrade pip

install docker-compose
# pip install docker-compose







一、
Docker Machine - 让你轻松部署Docker实例到很多不同的平台。
Docker Compose - Fig工具的替代品。
Docker Swarm - Docker众实例的原生集群。

这些工具可以简单的编排（orchestration ）Docker实例、集群以及容器管理。
这三种技术中，Swarm目前不适合在生产中使用。

二、
Mesos Marathon

三、
Kubernetes



Docker Compose




docker-compose文件内容区域

services : 服务，定义应用需要的一些服务，每个服务都有自己的名字、使用的镜像、挂载的数据卷、所属的网络、依赖哪些其他服务等等
networks : 网络，定义应用的名字、使用的网络类型等等
volumes : 数据卷，定义的数据卷（名字等等），然后挂载到不同的服务下去使用

4. docker-compose 实战　[ 多 web ] [ dockerfile 相关文章有介绍　]

   * 构建 nginx dockerfile 文件

#Base image
FROM centos:7
 
#Commands
RUN rpm -ivh http://mirrors.aliyun.com/epel/epel-release-latest-7.noarch.rpm
RUN yum install -y nginx
RUN echo "daemon off;" >> /etc/nginx/nginx.conf
 
EXPOSE 80
CMD ["nginx"]


   * 通过 dockerfile 文件构建镜像

[root@docker nginx]# docker build -t lisea/nginx:v1.0.1 .


   * 查看镜像

[root@docker nginx]# docker images
REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE
lisea/nginx         v1.0.1              ced9cfbd138f        23 minutes ago      387.2 MB
docker.io/centos    7                   3bee3060bfc8        12 days ago         192.5 MB


   * 构建 docker-compose 文件

        volumes中挂载的目录当宿主机不存在时，会自动创建

version: '2'
services:
  web1:
    image: lisea/nginx:v1.0.1
    volumes:
      - /data/www1:/usr/share/nginx/html
    ports:
      - "8080:80"
  web2:
    image: lisea/nginx:v1.0.1
    volumes:
      - /data/www2:/usr/share/nginx/html
    ports:
      - "8081:80"
  web3:
    image: lisea/nginx:v1.0.1
    volumes:
      - /data/www3:/usr/share/nginx/html
    ports:
      - "8082:80"


   * 使用docker-compose 开始构建容器 

     up 构建运行

　　 -d 后台运行


[root@docker nginx]# docker-compose up -d 
Creating network "nginx_default" with the default driver
Creating nginx_web2_1 ... 
Creating nginx_web3_1 ... 
Creating nginx_web1_1 ... 
Creating nginx_web2_1
Creating nginx_web3_1
Creating nginx_web1_1 ... done


   * 查看容器状态

[root@docker nginx]# docker-compose ps
    Name       Command   State          Ports         
-----------------------------------------------------
nginx_web1_1   nginx     Up      0.0.0.0:8080->80/tcp 
nginx_web2_1   nginx     Up      0.0.0.0:8081->80/tcp 
nginx_web3_1   nginx     Up      0.0.0.0:8082->80/tcp


   * 向web挂载目录添加内容

[root@harbor nginx]# echo "1 web" > /data/www1/index.html
[root@harbor nginx]# echo "2 web" > /data/www2/index.html 
[root@harbor nginx]# echo "3 web" > /data/www3/index.html


   * curl 访问测试

[root@docker nginx]# curl http://127.0.0.1:8080
1 web
[root@docker nginx]# curl http://127.0.0.1:8081
2 web
[root@docker nginx]# curl http://127.0.0.1:8082
3 web


   * 查看容器日志

[root@docker nginx]# docker-compose logs       
Attaching to nginx_web3_1, nginx_web1_1, nginx_web2_1


   * 停止并清除容器[ 需在docker-compose.yml文件同目录下,或 -f 指定docker-compose.yml路径 ]


[root@docker nginx]# docker-compose down
Stopping nginx_web1_1 ... done
Stopping nginx_web3_1 ... done
Stopping nginx_web2_1 ... done
Removing nginx_web1_1 ... done
Removing nginx_web3_1 ... done
Removing nginx_web2_1 ... done
Removing network nginx_default


5. docker-compose.yml 内容相关

　 * image：指定镜像，如果本地不存在，Compose会尝试去docker hub pull下来


image: centos
image: orchardup/postgresql  
image: a4bc65fd


   * build：指定Dockerfile文件的路径，Compose将会以一个已存在的名称进行构建并标记，并随后使用这个image


build: /path/to/build/dir


   * command：重写默认的命令


command: bundle exec thin -p 3000


   * links 连接到其他服务中的容器，可以指定服务名称和这个链接的别名，或者只指定服务名称


links:  
  - db   
  - db:database   
  - redis


   * external_links：连接到在这个docker-compose.yml文件或者Compose外部启动的容器，特别是对于提供共享和公共服务的容器。在指定容器名称和别名时，external_links遵循着和links相同的语义用法


external_links:  
  - redis_1   
  - project_db_1:mysql   
  - project_db_1:postgresql


   * ports：暴露端口，指定两者的端口（主机：容器），或者只是容器的端口（主机会被随机分配一个端口）


ports:  
  - "3000"   
  - "8000:8000"   
  - "49100:22"   
  - "127.0.0.1:8001:8001"


   * expose：暴露端口而不必向主机发布它们，而只是会向链接的服务（linked service）提供，只有内部端口可以被指定


expose:  
  - "3000"   
  - "8000"


   * volumes：挂载路径最为卷，可以选择性的指定一个主机上的路径（主机：容器），或是一种可使用的模式（主机：容器：ro）


volumes:  
  - /data/www:/usr/share/nginx/html
  - container_name


   * environment：加入环境变量，可以使用数组或者字典，只有一个key的环境变量可以在运行Compose的机器上找到对应的值，这有助于加密的或者特殊主机的值


environment:  
  RACK_ENV: development  
  SESSION_SECRET:  
environments:  
  - RACK_ENV=development    
  - SESSION_SECRET


   * env_file：从一个文件中加入环境变量，该文件可以是一个单独的值或者一张列表，在environment中指定的环境变量将会重写这些值

env_file:  
  - .env  
 
RACK_ENV: development


   * net: 网络模式，可以在docker客户端的--net参数中指定这些值


net: "bridge"  
net: "none"  
net: "container:[name or id]"  
net: "host"


   * dns 自定义DNS服务，可以是一个单独的值或者一张列表


dns: 8.8.8.8  
dns:  
  - 8.8.8.8    
  - 9.9.9.9


   * dns_search 自定义DNS搜索范围，可以是单独的值或者一张列表


dns_search: example.com  
dns_search:  
  - dc1.example.com  
  - dc2.example.com


   * working_dir,entrypoint,user,hostname,domainname,mem_limit,privileged,restart,stdin_open,tty,cpu_shares

上述的每一个都只是一个单独的值，和docker run中对应的参数是一样的

cpu_shares: 73
 
working_dir: /code
 
entrypoint: /code/entrypoint.sh
 
user: postgresql
 
hostname: foo
 
domainname: foo.com
 
mem_limit: 1000000000
 
privileged: true
 
restart: always
 
stdin_open: true
 
tty: true























1 image

services:
  web:
    image: hello-world
  
  services标签下二级标签为web
  image制定服务镜像名或镜像ID，如本地不存在尝试拉取镜像

2 build

build: /path/to/build/dir

  指定镜像或基于一份dockerfile，在使用up启动之时执行构建任务，构建镜像;
  然后使用镜像启动服务镜像

也可以是相对路径，只要上下文确定就可以读取到 Dockerfile。

build: ./dir
设定上下文根目录，然后以该目录为准指定 Dockerfile。

build:
  context: ../
  dockerfile: path/of/Dockerfile
注意 build 都是一个目录，如果你要指定 Dockerfile 文件需要在 build 标签的子级标签中使用 dockerfile 标签指定，如上面的例子。
如果你同时指定了 image 和 build 两个标签，那么 Compose 会构建镜像并且把镜像命名为 image 后面的那个名字。

build: ./dir
image: webapp:tag
既然可以在 docker-compose.yml 中定义构建任务，那么一定少不了 arg 这个标签，就像 Dockerfile 中的 ARG 指令，它可以在构建过程中指定环境变量，但是在构建成功后取消，在 docker-compose.yml 文件中也支持这样的写法：

build:
  context: .
  args:
    buildno: 1
    password: secret
下面这种写法也是支持的，一般来说下面的写法更适合阅读。

build:
  context: .
  args:
    - buildno=1
    - password=secret
与 ENV 不同的是，ARG 是允许空值的。例如：

args:
  - buildno
  - password
这样构建过程可以向它们赋值。

注意：YAML 的布尔值（true, false, yes, no, on, off）必须要使用引号引起来（单引号、双引号均可），否则会当成字符串解析。


3 command
使用 command 可以覆盖容器启动后默认执行的命令。

command: bundle exec thin -p 3000
也可以写成类似 Dockerfile 中的格式：
command: [bundle, exec, thin, -p, 3000]

4 container_name
前面说过 Compose 的容器名称格式是：<项目名称><服务名称><序号>
虽然可以自定义项目名称、服务名称，但是如果你想完全控制容器的命名，可以使用这个标签指定：

container_name: app
这样容器的名字就指定为 app 了。

5.depends_on
在使用 Compose 时，最大的好处就是少打启动命令，但是一般项目容器启动的顺序是有要求的，如果直接从上到下启动容器，必然会因为容器依赖问题而启动失败。
例如在没启动数据库容器的时候启动了应用容器，这时候应用容器会因为找不到数据库而退出，为了避免这种情况我们需要加入一个标签，就是 depends_on，这个标签解决了容器的依赖、启动先后的问题。
例如下面容器会先启动 redis 和 db 两个服务，最后才启动 web 服务：

version: '2'
services:
  web:
    build: .
    depends_on:
      - db
      - redis
  redis:
    image: redis
  db:
    image: postgres
注意的是，默认情况下使用 docker-compose up web 这样的方式启动 web 服务时，也会启动 redis 和 db 两个服务，因为在配置文件中定义了依赖关系。

6 dns
和 --dns 参数一样用途，格式如下：

dns: 8.8.8.8
也可以是一个列表：

dns:
  - 8.8.8.8
  - 9.9.9.9
此外 dns_search 的配置也类似：

dns_search: example.com
dns_search:
  - dc1.example.com
  - dc2.example.com
7 tmpfs
挂载临时目录到容器内部，与 run 的参数一样效果：

tmpfs: /run
tmpfs:
  - /run
  - /tmp



  #!/bin/bash

CONTAINER=(`docker ps -a | awk '$NF!="NAMES"{print $NF}'| xargs`)
_STATUS () {
#获取容器运行状态
for i in `seq 0 $((${#CONTAINER[@]}-1))`
do
    CONTAINER_STATUS=`docker inspect ${CONTAINER[$i]} -f '{{ .State.Running}}'`
    if [ $CONTAINER_STATUS == "true" ];then
        echo "1"
    else
        echo "0"
    fi
done
}
_CPU () {
#获取容器CPU使用率
for i in `seq 0 $((${#CONTAINER[@]}-1))`
do
  echo "`docker stats ${CONTAINER[$i]} --no-stream --format "table {{.CPUPerc}}" | awk -F"%" 'NR!=1{print $1}'`"
done
}
_MEM () {
#获取容器内存使用率
for i in `seq 0 $((${#CONTAINER[@]}-1))`
do
  echo "`docker stats ${CONTAINER[$i]} --no-stream --format "table {{.MemPerc}}" | awk -F"%" 'NR!=1{print $1}'`" 
done
}

case $1 in
  STATUS)
  _STATUS
  ;;
  CPU)
  _CPU
  ;;
  MEM)
  _MEM
  ;;
  *)
  echo "Usage: $PWD/`basename $0` {STATUS|CPU|MEM}"
  ;;
esac





docker run -e PARAMS="--spring.datasource.url=jdbc:mysql://yunupgroup.com:3306/xxl-conf?Unicode=true&characterEncoding=UTF-8 --spring.datasource.username=root --spring.datasource.password=123456" -p 8080:8080 -v /tmp:/data/applogs --name xxl-conf-admin  -d xuxueli/xxl-conf-admin:1.6.1


-----BEGIN CERTIFICATE-----
MIIC7jCCAdagAwIBAgIBADANBgkqhkiG9w0BAQsFADAoMRIwEAYDVQQKEwl0aGUt
cmFuY2gxEjAQBgNVBAMTCWNhdHRsZS1jYTAeFw0xOTAxMTQwNjQ4NDhaFw0yOTAx
MTEwNjQ4NDhaMCgxEjAQBgNVBAoTCXRoZS1yYW5jaDESMBAGA1UEAxMJY2F0dGxl
LWNhMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAvsc0E+JVf/qo4B2p
g7tMaMFfjK2NFciqabCnzP7fKLdOfGD6nlfbjWwYCFMET55O4FyT7OIkQlLjo34K
+0G3SFkfnYb+DQ+E/24InQmsH8XGc0bb0L8uZSQ2TkqCYCqhyqLWBhTePMfK3Ww0
KGl3XaTV7TlFwEBGulho/mZgDqScpNFMNSQ+We2oMuoom4lRVIl+XYkO8YfHBTTr
zRpK4H9mPh06Z/6qP4vQa3v/e+sAXy5+cGoAuACoWuRtfdnJFTTl+Pze4MO+9yBZ
1rrkGwb2Acyu9Jh3oGdvEdHU6m+LDgvepFogWjGQ1HWtiwSYiWtcbXFtesk4hzCG
LvxqZQIDAQABoyMwITAOBgNVHQ8BAf8EBAMCAqQwDwYDVR0TAQH/BAUwAwEB/zAN
BgkqhkiG9w0BAQsFAAOCAQEAYv3sNvOa+UdKLPndO1H5fZpcCbVqkwLgCRvpeXkJ
Bh0C/mdMevNuysamBVandIuIk60pDKKqmEpmX+yFlM/Eyrsk+/8YkDH4DoqOLFQG
GOMSGXFtZPZn9B9bgOLtFotpX3jqvr67tlgFE4M/Z6J3r0Tgo69ckMgRlTMjTIDA
TQyXpfcfbKQrOEEptdMHRyRi3kYiNHimmt6dkX8DAb+GK8d724hftuSRtsVxtUKf
D0AlubxK1hwyM8WJRacHMekmTBVOzcy5je+mCfcCxUgPWv/3AHv+aZ6qgtYWVvfe
KEM/gaUMGAYBlaC1/uFqNpfFBJPVMyd1oCbz2/hj6UrimQ==
-----END CERTIFICATE-----

tX9Jdb

ipset -N cdn iphash      #创建IPSET链
ipset -A cdn cdnIP  #接受的ip
ipset -L cdn             #检查IP地址列表






server {
    listen 80;
   	server_name _;
    if ($request_method !~ ^(GET|HEAD|POST)$ ) {
      return 403;
     }

    location / {
        root /usr/share/nginx/html;
        index index.html;
        try_files $uri $uri/ /index.html;
    }
    location ~* \.(html)$ {
        root /usr/share/nginx/html;
        add_header Cache-Control "no-cache, no-store";
	}
     location ^~ /1.0/ {
        proxy_pass       http://zb-web-tomcat:8080;
        proxy_redirect   off;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Host $server_name;
    }
    location ^~ /api/ {
        proxy_pass  http://zb_web_api;
        proxy_set_header Host $host;
        proxy_headers_hash_max_size 51200;
        proxy_headers_hash_bucket_size 6400;
        proxy_set_header X-Real-IP  $remote_addr;
        proxy_set_header X-Forwarded-For $http_x_forwarded_for;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header Access-Control-Allow-Origin $http_origin;
    }
}







apiVersion: extensions/v1beta1
kind: Ingress
  name: zun8000
  namespace: zb-web
spec:
  tls:
  - hosts:
    - zun20.com
    - zun400.com
    - www.zun8000.com
    secretName: 158zun
  rules:
  - host: zun20.com
    http:
      paths:
      - backend:
          serviceName: zb-web-frontend-1
          servicePort: 80
  - host: zun400.com
    http:
      paths:
      - backend:
          serviceName: zb-web-frontend-1
          servicePort: 80
  - host: www.zun8000.com
    http:
      paths:
      - backend:
          serviceName: zb-web-frontend-1
          servicePort: 80
status:
  loadBalancer:
    ingress:
    - ip: 69.172.86.207
    - ip: 69.172.86.208
    - ip: 69.172.86.209





tomcat_vue:
    image: harbor.easydevops.net/zb/zb_web_tomcat
    deploy:
      replicas: 3 
      restart_policy:
        condition: on-failure 
      resources:
        limits:
          memory: 4096M
    environment:
      TZ: "Asia/Shanghai"
    volumes:
      - "../zb_server/config.properties:/usr/local/tomcat/webapps/CODE/WEB-INF/classes/config.properties"
      - "../zb_server/init.properties:/usr/local/tomcat/webapps/CODE/WEB-INF/classes/init.properties"
      - "../zb_server/log4j.properties:/usr/local/tomcat/webapps/CODE/WEB-INF/classes/log4j.properties"
      - "../zb_server/context.xml:/usr/local/tomcat/conf/context.xml"
      - "/home/data/logs/zb_server/:/usr/local/tomcat/logs/"
      - "../zb_server/lib/commons-pool2-2.2.jar:/usr/local/tomcat/lib/commons-pool2-2.2.jar"
      - "../zb_server/lib/jedis-2.5.1.jar:/usr/local/tomcat/lib/jedis-2.5.1.jar"
      - "../zb_server/lib/tomcat8.5-redis-session-manager.jar:/usr/local/tomcat/lib/tomcat8.5-redis-session-manager.jar"








   
    


docker 网络
    docker的网络模式大致可以分成五种类型
    宿主机上会创建三个网络，分别是bridge网络，host网络，none网络，可以使用docker network ls命令查看。
    
1.none网络
    这种网络模式下容器只有lo回环网络，没有其他网卡。none网络可以在容器创建时通过--network=none来指定。
    这种类型的网络没有办法联网，封闭的网络能很好的保证容器的安全性。

2.host网络
    通过命令--network=host指定，使用host模式的容器可以直接使用docker host的IP地址与外界通信，
    容器内部的服务端口也可以使用宿主机的端口，不需要进行NAT，host最大的优势就是网络性能比较好，
    但是docker host上已经使用的端口就不能再用了，网络的隔离性不好。

3.bridge网络
    容器的默认网络模式，docker在安装时会创建一个名为docker0的Linux bridge，在不指定--network的情况下，创建的容器都会默认挂到docker0上面。
    创建一个容器之后一个新的网络接口被挂载到了docker0上，这个就是容器创建时创建的虚拟网卡。
    bridge模式为容器创建独立的网络栈，保证容器内的进程使用独立的网络环境，使容器之间，容器和docker host之间实现网络隔离。

4.container模式
    创建容器时使用 --network=container:NAME_or_ID 这个模式在创建新的容器的时候指定容器的网络和一个已经存在的容器共享一个Network Namespace，但是并不为docker容器进行任何网络配置
    这个docker容器没有网卡、IP、路由等信息，需要手动的去为docker容器添加网卡、配置IP等。

5.user-defined模式
    用户自定义模式主要可选的有三种网络驱动：bridge、overlay、macvlan。
    bridge驱动用于创建类似于前面提到的bridge网络；overlay和macvlan驱动用于创建跨主机的网络。





# Completed on Wed Feb 20 15:28:31 2019
# Generated by iptables-save v1.4.21 on Wed Feb 20 15:28:31 2019
*filter
:INPUT ACCEPT [0:0]
:FORWARD DROP [0:0]
:OUTPUT ACCEPT [8836:3590384]
:DOCKER-USER - [0:0]
-A INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT
-A INPUT -p icmp -m set --match-set ping src -j ACCEPT
-A INPUT -s 172.20.0.0/16 -j ACCEPT
-A INPUT -p icmp -m set --match-set zabbix src -j ACCEPT
-A INPUT -p icmp -j DROP
-A INPUT -i lo -j ACCEPT
-A INPUT -p tcp -m set --match-set ssh src -m tcp --dport 8384 -j ACCEPT
-A INPUT -p tcp -m set --match-set gateway src -m tcp --dport 8384 -j ACCEPT
-A INPUT -p tcp -m set --match-set zabbix src -m tcp --dport 10050 -j ACCEPT
-A INPUT -p tcp -m set --match-set rsync src -m tcp --dport 873 -j ACCEPT
-A INPUT -p tcp -m set --match-set cdn src -m multiport --dports 80,443,6336 -j ACCEPT
-A INPUT -p tcp -m set --match-set desktop_cloud src -m multiport --dports 80,443,6336,19999 -j ACCEPT
-A INPUT -j REJECT --reject-with icmp-host-prohibited
COMMIT
# Completed on Wed Feb 20 15:28:31 2019
# Generated by iptables-save v1.4.21 on Wed Feb 20 15:28:31 2019
*nat
:PREROUTING ACCEPT [28:1552]
:INPUT ACCEPT [15:900]
:OUTPUT ACCEPT [0:0]
:POSTROUTING ACCEPT [0:0]
-A POSTROUTING -j MASQUERADE
COMMIT
# Completed on Wed Feb 20 15:28:31 2019












sudo sh -c "cat > /etc/yum.repos.d/grafana.repo << EOF
[grafana]
name=grafana
baseurl=https://packages.grafana.com/oss/rpm
repo_gpgcheck=1
enabled=1
gpgcheck=1
gpgkey=https://packages.grafana.com/gpg.key
sslverify=1
sslcacert=/etc/pki/tls/certs/ca-bundle.crt
EOF
"



[[inputs.jolokia]]
  ## This is the context root used to compose the jolokia url
  ## NOTE that Jolokia requires a trailing slash at the end of the context root
  context = "/jolokia/"

  ## This specifies the mode used
  # mode = "proxy"
  #
  ## When in proxy mode this section is used to specify further
  ## proxy address configurations.
  ## Remember to change host address to fit your environment.
  # [inputs.jolokia.proxy]
  #   host = "127.0.0.1"
  #   port = "8080"
  
  ## Optional http timeouts
  ##
  ## response_header_timeout, if non-zero, specifies the amount of time to wait
  ## for a server's response headers after fully writing the request.
  # response_header_timeout = "3s"
  ##
  ## client_timeout specifies a time limit for requests made by this client.
  ## Includes connection time, any redirects, and reading the response body.
  # client_timeout = "4s"

  ## List of servers exposing jolokia read service
  [[inputs.jolokia.servers]]
    name = "zb-web-tomca"
    host = "zb-web-tomcat"
    port = "8778"
    # username = "myuser"
    # password = "mypassword"

  ## List of metrics collected on above servers
  ## Each metric consists in a name, a jmx path and either
  ## a pass or drop slice attribute.
  ## This collect all heap memory usage metrics.
  [[inputs.jolokia.metrics]]
    name = "heap_memory_usage"
    mbean  = "java.lang:type=Memory"
    attribute = "HeapMemoryUsage"

  ## This collect thread counts metrics.
  [[inputs.jolokia.metrics]]
    name = "thread_count"
    mbean  = "java.lang:type=Threading"
    attribute = "TotalStartedThreadCount,ThreadCount,DaemonThreadCount,PeakThreadCount"

  ## This collect number of class loaded/unloaded counts metrics.
  [[inputs.jolokia.metrics]]
    name = "class_count"
    mbean  = "java.lang:type=ClassLoading"
    attribute = "LoadedClassCount,UnloadedClassCount,TotalLoadedClassCount"


SHOW TAG VALUES FROM "Tablename" WITH KEY = "Keyword"




client := &http.Client{}
req, err := http.NewRequest("GET", lastChangeUrl, nil)
req.Header.Add("Authorization", appConfig.ApolloToken)
req.Header.Add("Content-Type", "application/json;charset=UTF-8")
resp, err := client.Do(req)

if err != nil {
    // handle error
    log.Println(err)
    return "nil"
}
defer resp.Body.Close()
body, err := ioutil.ReadAll(resp.Body)
if err != nil {
    // handle error
    log.Println(err)
    return "nil"
}
strBody := fmt.Sprintf(`%s`, string(body))





