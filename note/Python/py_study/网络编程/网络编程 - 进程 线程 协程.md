# 进程与线程
线程是操作系统能够进行运算调度的最小单位。它被包含在进程之中，是进程中的实际运作单位。一条线程指的是进程中一个单一顺序的控制流，一个进程中可以并发多个线程，每条线程并行执行不同的任务。

- 线程共享内存空间、进程的内存是独立的
- 同一个进程的线程之间可以直接通信，两个进程之间通信、需要中间代理实现
- 创建新线程简单，创建新进程需要对其父进程进行一次克隆
- 一个线程可以控制和操作同一进程里的其他线程，但是进程只能操作子进程
- 修改线程影响同一进程下的其它线程，修改进程、不影响其它进程

**IO操作不占用CPU，计算占用CPU。python多进程用于cpu密集操作性的任务，python多线程适合IO密集型的任务。**

# 多线程
## 线程的2种调用方式：threading模块
### 直接调用
```python
import threading
import time

def run(n):
    print(n)
    time.sleep(2)

t1 = threading.Thread(target=run, args=("t1",))
t2 = threading.Thread(target=run, args=("t2", ))

t1.start()
t2.start()

run("t1")
run("t2")
```

### 继承式调用
```python
import threading
import time

class MyThread(threading.Thread):
    def __init__(self, n):
        super(MyThread, self).__init__()
        self.n = n

    def run(self):
        print(self.n)
        time.sleep(2)

t1 = MyThread("t1")
t2 = MyThread("t2")

t1.start()
t1.join() #等待T1进程执行结束后再执行T2
t2.start()
```

## join & daemon(守护线程)
### join
```python
import threading
import time

start_time = time.time()
t_objs = []

def run(n):
    print(n)
    time.sleep(2)

for i in range(50):
    t = threading.Thread(target=run, args=("Task：t-%s" % i,))
    t.start()
    t_objs.append(t)

#join - (等待的意思)等所有子线程执行完之后在执行主线程，最后一个进程默认有一个join
for t in t_objs:
    t.join()

print("Thread done：", time.time() - start_time, threading.current_thread(), threading.active_count())

# threading.current_thread()  显示当前进程是主进程还是子进程
# threading.active_count()   显示当前活动的进程数
```

### daemon
```python
import threading
import time

start_time = time.time()
t_objs = []

def run(n):
    time.sleep(2)
    print("Task done", n, threading.current_thread(), threading.active_count())

for i in range(50):
    t = threading.Thread(target=run, args=("Task：t-%s" % i,))
    t.setDaemon(True)    #把当前线程设置为守护线程
    t.start()
    t_objs.append(t)

print("Cost time：", time.time() - start_time, threading.current_thread(), threading.active_count())
```

## 线程锁
- Lock是可用的最低级别的同步指令，一个线程只能请求一次，而RLock是可以被一个线程请求多次的同步指令(在同一个线程里可以多次申请锁，而Lock则不能，必须在释放之后才能再次申请)

  ```
  Lock.acquire()
  Lock.acquire()
  Lock.release()
  Lock.release()
  连续两次acquire请求，会导致死锁，因为第一次获得锁之后还没有释放，第二次再来申请，程序就阻塞在这里，导致第一次申请到的锁无法释放
  ```
- 当Lock处于锁定状态时，不被特定的线程所拥有，而RLock使用了“拥有的线程”和“递归等级”的概念，因此处于锁定状态时，可以被线程拥有

### Lock 线程锁(互斥锁)
一个进程下可以启动多个线程，多个线程共享父进程的内存空间，也就意味着每个线程可以访问同一份数据，此时如果两个线程同时要修改一份数据，会出现bug。

```
BUG实例：

import threading

balance = 0


def change_it_without_lock(n):
    global balance

    for i in range(100000):
        balance += 1
        balance -= 1

    print(balance)

threads = [
    threading.Thread(target=change_it_without_lock, args=(8, )),
    threading.Thread(target=change_it_without_lock, args=(10, ))
]

[t.start() for t in threads]
[t.join() for t in threads]

输出：
0
1
```
```python
import threading
import time


def run(n):
    lock.acquire()    #获取锁
    global num
    num += 1
    time.sleep(1)    #增加执行时间50秒、因为没释放锁、时间累积，尽可能获取锁之后尽快释放
    lock.release()    #释放锁

lock = threading.Lock()    #定义锁
num = 0
t_obj = []

for i in range(100):
    t = threading.Thread(target=run, args=("Task：t-%s" % i,))
    t.start()
    t_obj.append(t)

for i in t_obj:
    i.join()

print(num)
```

### RLock 线程锁(递归锁)
一把大锁中还包含子锁
```python
import threading,time

def run1():
    print("grab the first part data")
    lock.acquire()
    global num
    num +=1
    lock.release()
    return num
def run2():
    print("grab the second part data")
    lock.acquire()
    global  num2
    num2+=1
    lock.release()
    return num2
def run3():
    lock.acquire()
    res = run1()
    print('--------between run1 and run2-----')
    res2 = run2()
    lock.release()
    print(res,res2)


if __name__ == '__main__':

    num,num2 = 0,0
    lock = threading.RLock()
    for i in range(10):
        t = threading.Thread(target=run3)
        t.start()

while threading.active_count() != 1:
    print(threading.active_count())
else:
    print('----all threads done---')
    print(num,num2)
```

### 信号量
互斥锁 同时只允许一个线程更改数据，而Semaphore是同时允许一定数量的线程更改数据
```python
import threading,time

def run(n):
    semaphore.acquire()
    time.sleep(1)
    print("run the thread: %s\n" %n)
    semaphore.release()

if __name__ == '__main__':

    semaphore  = threading.BoundedSemaphore(5) #最多允许5个线程同时运行
    for i in range(20):
        t = threading.Thread(target=run,args=(i,))
        t.start()

while threading.active_count() != 1:
    pass #print threading.active_count()
else:
    print('----all threads done---')
```

## Events
### Events方法
```
An event is a simple synchronization object;

the event represents an internal flag, and threads
can wait for the flag to be set, or set or clear the flag themselves.

event = threading.Event()

# a client thread can wait for the flag to be set
event.wait()    #等待设置flag

# a server thread can set or reset it
event.set()    #设定flag
event.is_set()    #是否被设定
event.clear()    #没有设置
If the flag is set, the wait method doesn’t do anything.
If the flag is cleared, wait will block until it becomes set again.
Any number of threads may wait for the same event.
```

### Events示例
```python
import threading
import time

event = threading.Event()


def lighter():
    count = 0
    event.set()
    while True:
        if count > 4 and count < 10:
            event.clear()
            print("\033[41;1m Red light is on .... \033[0m")
        elif count > 10:
            event.set()
            count = 0
        else:
            print("\033[44;1m Green light is on .... \033[0m")
        time.sleep(1)
        count += 1


def car(name):
    while True:
        if event.is_set():
            print("【%s】 running..." % name)
            time.sleep(1)
        else:
            print("【%s】 sees red light, waiting... " % name)
            event.wait()
            print("\033[34;1m 【%s】 green light is on, start going... \033[0m" % name)

light = threading.Thread(target=lighter)
light.start()

car1 = threading.Thread(target=car, args=("兰博基尼",))
car2 = threading.Thread(target=car, args=("阿斯顿马丁",))
car1.start()
car2.start()
```

## queue队列
```python
class queue.Queue(maxsize=0)    #先入先出
class queue.LifoQueue(maxsize=0)    #Lifo = last in fisrt out 后入先出
class queue.PriorityQueue(maxsize=0)    #存储数据时可设置优先级的队列 q.put(1， “date1”)  q.put(5, "date2")

eg:
q = queue.Queue()
q.put("data1")
q.put("data2")

q.qsize() 队列长度

q.get()
q.get()
q.get_nowait()  #如果没有数据就退出、get没有数据就会死等或者 get(block=False, timeout=1)  关闭等待或者设置等待时长
```

## 生产者消费者模型
```
import threading
import queue

def producer():
    for i in range(10):
        q.put("骨头 %s" % i )

    print("开始等待所有的骨头被取走...")
    q.join()
    print("所有的骨头被取完了...")

def consumer(n):
    while q.qsize() >0:
        print("%s 取到" %n  , q.get())
        q.task_done() #告知这个任务执行完了

q = queue.Queue()

p = threading.Thread(target=producer,)
p.start()

c1 = consumer("李闯")
```

# 多进程
## 进程调用
```python
#循环10个进程，每个进程下开启一个线程
import multiprocessing
import threading
import time

def run_thread():
    t_id = threading.get_ident()
    print(t_id)

def run(name):
    time.sleep(1)
    print("Hello", name)
    t = threading.Thread(target=run_thread, )
    t.start()

if __name__ == "__main__":
    for i in range(10):
        p = multiprocessing.Process(target=run, args=("Running processing <%s>" % i, ))
        p.start()
```

## 进程ID
```python
import time, os
import multiprocessing


def info(title):
    print(title)
    print("module name", __name__)
    print("parent process ID：", os.getppid())
    print("sub process ID：", os.getpid())
    print("\n\n")


def f(name):
    info("\033[31;1m function f \033[0m")
    print("hello", name)


if __name__ == '__main__':
    info("\033[32;1m main process line \033[0m")
    p = multiprocessing.Process(target=f, args=("bob",))
    p.start()
    p.join()

# 结论： 所有的子进程都是由父进程启动的
```

## 进程间通讯
### Queues(队列)
使用方法和threading里的queue差不多,用来进程间通讯
```python
from multiprocessing import Process, Queue

def f(q):
    q.put([42, None, 'hello'])

if __name__ == '__main__':
    q = Queue()
    p = Process(target=f, args=(q,))
    p.start()
    print(q.get())    # prints "[42, None, 'hello']"
    p.join()

# 必须使用进程的queque(通过pickle序列化和反序列化数据实现通信，并不是共享同一个对象)、线程的queque是不允许的
```

### Pipes(管道)
用来实现子进程和父进程之间通讯
```python
from multiprocessing import Process, Pipe

def f(conn):
    conn.send([42, None, 'hello'])
    conn.close()

if __name__ == '__main__':
    parent_conn, child_conn = Pipe()
    p = Process(target=f, args=(child_conn,))
    p.start()
    print(parent_conn.recv())   # prints "[42, None, 'hello']"
    p.join()
```

### Managers
用来实现进程间的数据共享
```
from multiprocessing import Process, Manager
import os

def f(d, l):
    d[os.getpid()] = os.getpid()
    l.append(os.getpid())
    print(l)

if __name__ == '__main__':
    with Manager() as manager:
        d = manager.dict()    #定义一个字典
        l = manager.list(range(5))    #定义一个列表
        p_list = []
        for i in range(10):
            p = Process(target=f, args=(d, l))
            p.start()
            p_list.append(p)
        for res in p_list:
            res.join()

        print(d)
        print(l)
```

### 进程同步(进程锁)
目的控制屏幕输出、输出内容不会混乱
```python
from multiprocessing import Process, Lock

def f(l, i):
    l.acquire()
    try:
        print('hello world', i)
    finally:
        l.release()

if __name__ == '__main__':
    lock = Lock()

    for num in range(10):
        Process(target=f, args=(lock, num)).start()
```

## 进程池
进程池内部维护一个进程序列，当使用时，则去进程池中获取一个进程，如果进程池序列中没有可供使用的进程，那么程序就会等待，直到进程池中有可用进程为止。进程池中有两个方法：apply(同步执行)和apply_async(异步执行)
```python
from  multiprocessing import Process,Pool
import time

def Foo(i):
    time.sleep(2)
    return i+100

def Bar(arg):
    print('-->exec done:',arg)

pool = Pool(5)    #允许进程池同时放入5个进程

for i in range(10):
    pool.apply_async(func=Foo, args=(i,), callback=Bar)    #并行 callback --->回调 执行完毕Foo，继续执行Bar。并且是主进程执行
    #pool.apply(func=Foo, args=(i,))    #串行

print('end')
pool.close()
pool.join()#进程池中进程执行完毕后再关闭，如果注释，那么程序直接关闭。
```
